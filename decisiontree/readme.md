# 决策树算法
csdn博客总结 https://blog.csdn.net/qq_39751437/article/details/86550287

决策树是一种基本的分类回归方法，由结点和有向边组成，结点有两种类型，内部结点和叶节点，内部结点表示属性或特征，叶节点表示类别，呈树形结构决策树可以看成是定义在特征空间和类空间上的条件概率分布，也可以看成if-then规则集合，每一个实例都被一条路和一个规则所覆盖，而且只被一条覆盖。

## (1)算法思路：

三个步骤：特征选择–决策树的生成–决策树的剪枝

## (2)决策树算法本质

从if-then规则集合角度来看，决策树本质是从训练数据归纳出一组分类规则，可能有多种分类规则，选择与训练数据矛盾最小的规则，同时具有较好的泛化能力。
从条件概率角度来看，决策数本质是学习由训练数据集估计的条件概率模型，选择条件概率模型的依据是不仅能对训练数据有较好的拟合，而且对位置数据也有很好的预测。
从if-then规则集合角度来看，决策树本质是从训练数据归纳出一组分类规则，可能有多种分类规则，选择与训练数据矛盾最小的规则，同时具有较好的泛化能力。
从条件概率角度来看，决策数本质是学习由训练数据集估计的条件概率模型，选择条件概率模型的依据是不仅能对训练数据有较好的拟合，而且对位置数据也有很好的预测

## (3)常用算法

ID3

C4.5

CART

ID3决策树通常选择信息增益最大的特征来生成决策树。

C4.5决策树通常选择信息增益比最大的特征来生成决策树。

CART决策树通常选择基尼指数最小的特征来生成决策树。
