# K-近邻算法

(csdn博客总结https://blog.csdn.net/qq_39751437/article/details/86133047)

KNN 是一种分类与回归方法，属于监督学习一种。确定了KNN三要素，待预测点的分类也唯一确定。K-近邻模型基于对训练数据集特征空间的划分。

优点：精度高、对异常值不敏感、无数据输入假定。

缺点：计算复杂度高、空间复杂度高。 适用数据范围：数值型和标称型。

KNN三个基本要素
### （1）K值
K较大，会减少估计误差，增大近似误差，模型简单，近似误差越小，训练误差越小。
K较小，会增大近似误差，减少估计误差，估计误差越小，测试误差越小。模型复杂，容易过拟合。
通常采用交叉验证方法来选取K值

### （2）分类决策规则
通常用少数服从多数方法来决定待预测的类别，即给定K值和距离度量方式后，选取区域内离待分类点最近的K个目标，这些选定目标中类别出现最多的为待预测点的类别。分类决策规则对应于经验风险最小化。

### （3）距离度量方式
距离度量方式选择通常有两种，欧几里得距离，曼哈顿距离，注意，不同距离度量方式选取的近邻点不同


## 简要说明，以下代码全部在python3下运行
## MNIST-keras.py是用keras搭建的CNN模型识别手写数字
## choose best k.py是用交叉验证法选择最好的k函数，可直接调用
## kNN-mnist-sklearn.py是调用sklearn KNN接口 KNeighborsClassifier 完成手写图片识别
## kNN.py是机器学习实战源代码，包括约会预测，手写图片识别，其中用的训练数据集在trainingDigits1文件夹下，测试数据集在testDigits文件夹下，解压到当前目录即可
